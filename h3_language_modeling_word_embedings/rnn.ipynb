{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# Generating Shakespeare with a Character-Level RNN\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this part, we'll turn from traditional n-gram based language models to a more advanced form of language modeling using a Recurrent Neural Network. Specifically, we'll be setting up a character-level recurrent neural network (char-rnn) for short.\n",
    "\n",
    "Andrej Karpathy, a researcher at OpenAI, has written an excellent blog post about using RNNs for language models, which you should read before beginning this assignment.  The title of his blog post is [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n",
    "\n",
    "Karpathy shows how char-rnns can be used to generate texts for several fun domains:\n",
    "* Shakespeare plays\n",
    "* Essays about economics\n",
    "* LaTeX documents\n",
    "* Linux source code\n",
    "* Baby names\n",
    "\n",
    "# Recommended Reading\n",
    "\n",
    "You should install PyTorch, know Python, and understand Tensors:\n",
    "\n",
    "* http://pytorch.org/ For installation instructions\n",
    "* [Deep Learning with PyTorch: A 60-minute Blitz](https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb) to get started with PyTorch in general\n",
    "* [jcjohnson's PyTorch examples](https://github.com/jcjohnson/pytorch-examples) for an in depth overview\n",
    "* [Introduction to PyTorch for former Torchies](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb) if you are former Lua Torch user\n",
    "\n",
    "It would also be useful to know about RNNs and how they work:\n",
    "\n",
    "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) shows a bunch of real life examples\n",
    "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) is about LSTMs specifically but also informative about RNNs in general\n",
    "\n",
    "Also see these related tutorials from the series:\n",
    "\n",
    "* [Classifying Names with a Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) uses an RNN for classification\n",
    "* [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb) builds on this model to add a category as input\n",
    "\n",
    "## You can also set up Pytorch in Google Colab\n",
    "\n",
    "Pytorch is one of the most popular deep learning frameworks in both industry and academia, and learning its use will be invaluable should you choose a career in deep learning. \n",
    "\n",
    "### Setup\n",
    "#### Using Google Colab (recommended)\n",
    "1. Upload this notebook on [Colab](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
    "2. Set hardware accelerator to ```GPU``` under ```notebook settings``` in the ```Edit``` menu.\n",
    "3. Run the first cell to  set up  the environment.\n",
    "\n",
    "### Note\n",
    "Please look at the FAQ section before you start working.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare data\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = unidecode.unidecode(open('shakespeare_data/shakespeare_input.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "file_len = 4573338\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make inputs out of this big string of data, we will be splitting it into chunks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "thank\n",
      "God I have as little patience as another man; and\n",
      "therefore I can be quiet.\n",
      "\n",
      "DON ADRIANO DE ARMADO:\n",
      "I do affect the very ground, which is base, where\n",
      "her shoe, which is baser, guided by her foot,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the Model\n",
    "\n",
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution. You need to finish the forward method. (Refer to [Pytorch GRU Documentation](https://pytorch.org/docs/stable/nn.html#gru))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        #Input input: torch Tensor of shape (1,)\n",
    "        #hidden: torch Tensor of shape (self.n_layers, 1, self.hidden_size)\n",
    "        #Return output: torch Tensor of shape (1, self.output_size) \n",
    "        #and hidden: torch Tensor of shape (self.n_layers, 1, self.hidden_size)\n",
    "        encoded = self.encoder(input)\n",
    "        # encoded = encoded.squeeze(0)\n",
    "        # print(encoded.view())\n",
    "        # print(hidden.view())\n",
    "        encoded = encoded.unsqueeze(0)\n",
    "        encoded = encoded.unsqueeze(0)\n",
    "        output, hidden = self.gru(encoded,hidden)\n",
    "        # hidden = hidden.view(n_layers, n_directions=1, batch_size=1, hidden_dim=self.hidden_size)\n",
    "        # hidden = hidden[-1]\n",
    "        # output = output.squeeze(1)\n",
    "        # hidden_forward, hidden_backward = hidden[0], hidden[1]\n",
    "        out = self.decoder(output)\n",
    "        out = out.squeeze(1)\n",
    "        return out, hidden\n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inputs and Targets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long().to(device)\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([10, 11, 12, 39, 40, 41], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)[0]\n",
    "\n",
    "\n",
    "    return predicted"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A helper to print the amount of time passed:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The main training function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target.unsqueeze(1)[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / chunk_len"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we define the training parameters, instantiate the model, and start training:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 2\n",
    "lr = 0.001\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers).to(device)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0m 13s (100 5%) 2.8362]\n",
      "Wht at Biton iw oac, aco reast for hathrers mhe to, ahm fn iched th hof at ut:\n",
      "To nont hoth\n",
      "tot,\n",
      "Tht l \n",
      "\n",
      "[0m 27s (200 10%) 2.4487]\n",
      "Whot ot hhe no the,\n",
      "Dasd sare id sire fher cit en?\n",
      "\n",
      "EACMCEAp:, ansdam, not me nor,, she me yo we, you  \n",
      "\n",
      "[0m 41s (300 15%) 2.2000]\n",
      "Whe this, thou?\n",
      "\n",
      "MEAREU:\n",
      "\n",
      "For; in louns she of a end a the welor, and I the wery and ho Ay a me to is  \n",
      "\n",
      "[0m 55s (400 20%) 2.1136]\n",
      "Wher correse in at'tay greertringen:\n",
      "Tor eostes wothhave mathes is thester, mods corluy he thir cowen  \n",
      "\n",
      "[1m 8s (500 25%) 2.0062]\n",
      "Whan ere to you ent foan to ta in.\n",
      "\n",
      "CEAN:\n",
      "Mat old senth lemy fore, and the of me all aping they the th \n",
      "\n",
      "[1m 22s (600 30%) 2.2487]\n",
      "Wher thousan cleas you wive fare is yould the to sale hare ham.\n",
      "\n",
      "HTINTO:\n",
      "Prost that befastent more be  \n",
      "\n",
      "[1m 36s (700 35%) 1.9990]\n",
      "Whelker thy thear yould old\n",
      "Wir will lown thus gord ould she me storoar that of mebless bolderes mun a \n",
      "\n",
      "[1m 49s (800 40%) 2.0068]\n",
      "Wher that I the with thage.\n",
      "\n",
      "OTINA:\n",
      "She the that we lord bofuad shet in have alse and thy for-wheran:\n",
      " \n",
      "\n",
      "[2m 3s (900 45%) 2.0764]\n",
      "What it your mast that even, is houndpries will theman tame whoo's,\n",
      "He damy, what thead, of hike,\n",
      "Whel \n",
      "\n",
      "[2m 17s (1000 50%) 2.0023]\n",
      "Whal,\n",
      "Thy hith our shut-sent gorther with to drentand wourd,\n",
      "Won! hen groito for dristrien, would it b \n",
      "\n",
      "[2m 30s (1100 55%) 2.0064]\n",
      "Wheld by Romovere his the costder to mise:\n",
      "Sif ye cise eremeading so, we bettere,\n",
      "But wand I lestats s \n",
      "\n",
      "[2m 44s (1200 60%) 1.9589]\n",
      "Whelby!\n",
      "Nart thy croy's brod, forth then not lords,\n",
      "And the were casins colth and comuch well'd\n",
      "Prow t \n",
      "\n",
      "[2m 57s (1300 65%) 1.8900]\n",
      "Whair fruath,.\n",
      "Net there entlest it hath and to the father hast to my ince have his do my to my have p \n",
      "\n",
      "[3m 11s (1400 70%) 1.7337]\n",
      "Wher scans or theee frows there:\n",
      "You; it with my his an shill you whoy, of mosing all not doobk shall  \n",
      "\n",
      "[3m 25s (1500 75%) 1.7519]\n",
      "Wher for the all mist the and\n",
      "And of is brot, hand hatring,\n",
      "Aring he chave wouls it shall and you the  \n",
      "\n",
      "[3m 38s (1600 80%) 1.8131]\n",
      "Whan too dount of you swarrus and this westal\n",
      "Hood his greed thus: I'll my lean.\n",
      "\n",
      "DOBEL:\n",
      "Caistor him-p \n",
      "\n",
      "[3m 52s (1700 85%) 1.8427]\n",
      "Why good dane?\n",
      "\n",
      "Servion furt the stay sons,\n",
      "The his culso more fall of that lide.\n",
      "\n",
      "LANGHIRA:\n",
      "Were he f \n",
      "\n",
      "[4m 6s (1800 90%) 1.8984]\n",
      "Where shall of it told with the chanry now on conting\n",
      "shall did you see-thing brow he man:\n",
      "whither too \n",
      "\n",
      "[4m 20s (1900 95%) 1.8849]\n",
      "Where there same, send of\n",
      "not to the mone thee not daused do my efrech?\n",
      "Therefore hou duck 'to shourse \n",
      "\n",
      "[4m 33s (2000 100%) 1.7411]\n",
      "Whine his feart I have cains fried?\n",
      "\n",
      "SALGO:\n",
      "And what you\n",
      "have with shall be of the way.\n",
      "\n",
      "ACBECLESS:\n",
      "Sh \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting the Training Losses\n",
    "\n",
    "Plotting the historical loss from all_losses shows the network learning:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4503019400>]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating at different \"temperatures\"\n",
    "\n",
    "In the `evaluate` function above, every time a prediction is made the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. As we turn the temperature towards zero we are choosing only the most likely outputs.\n",
    "\n",
    "We can see the effects of this by adjusting the `temperature` argument."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(evaluate('Th', 200, temperature=0.8))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ther hape, in that trut would\n",
      "What uncuralm. I wall the malion.\n",
      "\n",
      "CIRLUS:\n",
      "I should us didst for not to that the drowht.\n",
      "\n",
      "AUNIL:\n",
      "If the have scallow so nou wild thou werick so man,\n",
      "The drangent: thou prow\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lower temperatures are less varied, choosing only the more probable outputs:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(evaluate('Th', 200, temperature=0.2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There a prainter the will the brown the will the will and the for the some to the such the could the are the are and the prince and the some to the come\n",
      "And the should the say the lord the sentle the co\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Higher temperatures more varied, choosing less probable outputs:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(evaluate('Th', 200, temperature=1.4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thelect of. wOHLCIAN:\n",
      "Arfoild,\n",
      "As spited tnog, soullque not britalh,\n",
      "Thou rin yamethou was vare surbWhom hand.\n",
      "\n",
      "MOFY FABlAnd,, O witherhart for now this\n",
      "Sapinemes's ome joget a fly oone son\n",
      "furmpy.\n",
      "T.'\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import torch.nn.functional as F\n",
    "def perp(testfile):\n",
    "    inp = char_tensor(testfile[:-1]).to(device)\n",
    "    target = char_tensor(testfile[1:]).to(device)\n",
    "    test_len=len(testfile)\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    perplexity=torch.tensor(0.0).to(device)\n",
    "\n",
    "    for c in range(test_len-1):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        perplexity -=F.log_softmax(output,dim=1)[0][target[c]]\n",
    "\n",
    "    return (perplexity/test_len).exp().item()\n",
    "\n",
    "testfile = unidecode.unidecode(open('shakespeare_data/shakespeare_sonnets.txt').read())\n",
    "print('Perplexity:',perp(testfile))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Perplexity: 6.900490760803223\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FAQs\n",
    "\n",
    "#### I'm unfamiliar with PyTorch. How do I get started?\n",
    "If you are new to the paradigm of computational graphs and functional programming, please have a look at this [tutorial](https://hackernoon.com/linear-regression-in-x-minutes-using-pytorch-8eec49f6a0e2) before getting started.\n",
    "\n",
    "#### How do I speed up training?\n",
    "Send the model and the input, output tensors to the GPU using ```.to(device)```. Refer the [PyTorch docs](https://pytorch.org/docs/stable/notes/cuda.html) for further information.\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "fd4653ffb3619e38e0f162702933cb5a2e71428b78fc95dca1bdeccba0429964"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}